{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from collections import Counter\n",
    "#Import mrcnn module\n",
    "import mrcnn.config as conf\n",
    "import mrcnn.model as model\n",
    "import visualize_1 as visual\n",
    "import skimage.io\n",
    "\n",
    "\n",
    "ROOT_DIR=os.path.abspath(\"/home/noor/projects/car parking/\")\n",
    "\n",
    "#Directory to save trained model\n",
    "MODEL_DIR=os.path.join(ROOT_DIR,\"model\")\n",
    "\n",
    "#Coco weights file path\n",
    "WEIGHT_DIR=os.path.join(ROOT_DIR,\"mask_rcnn_coco.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors(class_names):\n",
    "    np.random.seed(12)\n",
    "    rand_colors=[tuple(np.random.rand(3)*255) for _ in range(len(class_names))]\n",
    "    return rand_colors\n",
    "colour=colors(class_names)\n",
    "dict_color={ID:color for (ID,color) in enumerate(colour) }\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image,mask,color,alpha):\n",
    "    for i in range(3):\n",
    "        image[:,:,i]=np.where(mask==1,image[:,:,i]*(1-alpha)+alpha*color[i],image[:,:,i])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayinstances(image,masks,class_ids,class_names,scores,boxes):\n",
    "    N=boxes.shape[0]\n",
    "    if not N:\n",
    "        pass\n",
    "    else:\n",
    "        assert  N==masks.shape[-1]==class_ids.shape[0]\n",
    "        \n",
    "    \n",
    "    for i in range(N):\n",
    "         if not np.any(boxes[i]) or label!=\"car\" or label!=\"bicycle\" or label!=\"motorcycle\" or label!=\"bus\" or label!=\"truck\":\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping or label is not required vehicle\n",
    "             continue\n",
    "         class_id = class_ids[i]       \n",
    "         label = class_names[class_id]\n",
    "         y1, x1, y2, x2 = boxes[i]\n",
    "         score = scores[i] if scores is not None else None\n",
    "         color = dict_color[class_id]\n",
    "         caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "         mask = masks[:, :, i]\n",
    "         image = apply_mask(image, mask, color,0.5)\n",
    "         image = cv2.rectangle(image,(x1,y1),(x2,y2),color,2)\n",
    "         image = cv2.putText(image,caption,(x1,y1),cv2.FONT_HERSHEY_PLAIN,0.5,color,2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           PARK\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inherit from base class Config\n",
    "class parkconfig(conf.Config):\n",
    "    #batch_size=GPU_COUNT*IMAGES_PER_GPU\n",
    "    #GPU_COUNT=1\n",
    "      NAME=\"PARK\"\n",
    "      IMAGES_PER_GPU= 1\n",
    "      NUM_CLASSES=80+1\n",
    "config=parkconfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noor/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#create inference(testing) model\n",
    "Model=model.MaskRCNN(mode=\"inference\",config=config,model_dir=MODEL_DIR)\n",
    "\n",
    "#load pretrained weights for the model\n",
    "Model.load_weights(filepath=WEIGHT_DIR,by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"car_highway.mp4\")\n",
    "while(cap.isOpened()):#returns true if capture is initialized already\n",
    "    ret,frame=cap.read()#read frame\n",
    "    if ret:\n",
    "        output=Model.detect(images=[frame],verbose=0)#return list of dictionaries(one dict per image)\n",
    "        out=output[0]#first element of the list\n",
    "        image=displayinstances(frame,out[\"masks\"],out[\"class_ids\"],class_names,out[\"scores\"],out[\"rois\"])\n",
    "        \n",
    "        RGB_img= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow(\"image\",RGB_img)\n",
    "    if cv2.waitKey(100) & 0xFF==ord(\"q\"):#waits for 1 millisecond or press q to exit\n",
    "        break     \n",
    "cap.release()#close the video file or capturing device(s)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
